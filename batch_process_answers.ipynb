{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PPRS: Week 11\n",
    "# Spatial data analysis and batch processing in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this to display graphs nicely in this notebook\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This week we will use python to process a large set of data. GIS allows us to visually assess and interact with each step, whilst python allows us to easily scale up to processing large datasets with a single button press, making repeat processing easy. This follows on from the introduction to lidar session and is meant as an introduction to OOSA. We will use lidar data to map biomass along the Spey river valley.\n",
    "\n",
    "Tasks for you to complete are written in **bold font**.\n",
    "\n",
    "\n",
    "## Data\n",
    "\n",
    "We are using the DTM and DSM provided by the [Scottish government](https://remotesensingdata.gov.scot/data#/list). These were collected as point clouds and then processed to a DTM and DSM in geotiff format. After cloning these will be in the ***data*** directory. The raw data comes in 1 m resolution but the ALS point density was a little too low to support that, so we have coarsened it first to 3 m, taking the mean elevation for the DTM and the maximum elevation for the DSM, and then to 10 m taking the mean for both. Due to disk space limits on noteable, the data has already been coarsened for you.\n",
    "\n",
    "The 10 m resolution DTM and DSMs are available in the folders below in geotiff raster format:\n",
    "\n",
    "    data/ALS/DTM\n",
    "    data/ALS/DSM\n",
    "\n",
    "You can download some of these tiles to your computer and view them in QGIS if you would like. Or you can use some of the plotting functions within python to view them here.\n",
    "\n",
    "This week we will use the rasterio package to open our data. Below you will see code which uses this module and its functions to open and read GeoTIFF files. Note that there are many Python modules out there, some with overlapping functionality. The [rasterio manual](https://rasterio.readthedocs.io/en/stable/) shows the many options available within that package.\n",
    "\n",
    "Note that our geotiff has some missing data, labelled as -999. We can filter out to allow you to calculate metrics on the data only using the *not a number* variable, *nan*. We do this using an array *slice*. Slicing is a powerful tool in python to allow us to extract subsets of data using any logical expression. Here we are taking all the elements where *data is less than 0* and setting those to *nan*.\n",
    "\n",
    "**Run the cell below to get the data into memory (RAM) and print out some of the meta data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the necessary packages\n",
    "import numpy as np\n",
    "from sys import exit\n",
    "import rasterio\n",
    "\n",
    "\n",
    "# set a filename\n",
    "filename='data/ALS/DSM/coarsen.NN89_10M_DSM_PHASE1.tif'\n",
    "\n",
    "# read the data into a rasterio object\n",
    "datafile=rasterio.open(filename)\n",
    "\n",
    "# read the first band\n",
    "data=datafile.read(1)\n",
    "\n",
    "# label missing data as \"not a number\", nan\n",
    "data[data<0.0] = np.nan\n",
    "\n",
    "# read the geolocation meta data\n",
    "# note that the rasterio object contains many more variables. See the manual\n",
    "res=datafile.res\n",
    "nX=datafile.width\n",
    "nY=datafile.height\n",
    "\n",
    "# let us pring some of these to screen to see them\n",
    "print('x resolution',round(res[0],2),'m. y resolution',round(res[1],2),'m')\n",
    "print('The raster has',nX,'by',nY,'pixels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our data is in RAM, we can manipulate it in anyway we like. We can use the numpy functions to calculate some summary statistics of the data, as below. Before calculating the statistics we remove the missing data values (nan). We do this using another array *slice*. Here we are taking all the elements where *data equal to nan is False*, so all the real values for data, and saving this in a new array callied *usableData*. Note that this new *usableData* array will not be a rectangle so cannot be displayed as an image with imshow() anymore.\n",
    "\n",
    "**Add some lines to the end of the cell to calculate and print the minimum and maximum elevation for this tile, using the np.min() and np.max() functions.**\n",
    "\n",
    "Note that you can use the \"round(x,2)\" function to output to a sensible degree of precision and make it more readable. The manual for round is [here](https://docs.python.org/3/library/functions.html#round)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove missing data\n",
    "usableData=data[np.isnan(data)==False]\n",
    "\n",
    "# mean elevation\n",
    "meanElev=np.mean(usableData)\n",
    "print('Mean elevation is',round(meanElev,2),'m')\n",
    "\n",
    "# some measure of roughness\n",
    "stdevElev=np.std(usableData)\n",
    "print('The standard deviation of elevation is',round(stdevElev,2),'m')\n",
    "\n",
    "# calculate and print the min and max elevation\n",
    "minElev=np.min(usableData)\n",
    "maxElev=np.max(usableData)\n",
    "\n",
    "print('Min',minElev,'m. max',maxElev,'m')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image maps\n",
    "\n",
    "It is very useful to be able to plot images of our data to quickly asses it and check for artefacts. Calling `plt.imshow(data)` will now make an image map. This is part of the same package we used to plot data in the python foundations notebook, but is set up for making 2D images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot the 2D raster layer  \n",
    "plt.imshow(data)   # plot the 2D image\n",
    "plt.colorbar(label='Elevation (m)')     # add a colour bar\n",
    "plt.show()         # print to screen \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping biomas\n",
    "\n",
    "Now we can have some 10 m resolution DTM and DSM tiles and functions to read them in to RAM.\n",
    "\n",
    "### Canopy height map\n",
    "\n",
    "The first step was to make a canopy height map, CHM, which we can use to first calibrate a model between our lidar measurement and some ground biomass data, and then predict biomass across our site. To do this we need to read the DTM and DSM in to RAM as numpy arrays, filter missing data and then subtract the DTM from the DSM to make a new CHM array. This is quite a few lines of code and so we have grouped it into a \"user defined function\". This is a set of instructions that we can call throughout the program and allows us to write compact, readable and reusable code.\n",
    "\n",
    "**Add some lines to the end of this cell to plot the CHM you have just made.**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure you have run the readTiff() cell above to load that function.\n",
    "\n",
    "def heightAboveGround(dtmName,dsmName):\n",
    "    '''\n",
    "    A function to calculate height above ground from a DTM and DSM\n",
    "    Note that this assumes the two datasets are aligned and the same resolution\n",
    "    '''\n",
    "    \n",
    "    # open the DTM and DSM and read data\n",
    "    dtmFile=rasterio.open(dtmName)\n",
    "    dtm=dtmFile.read(1)\n",
    "    dsmFile=rasterio.open(dsmName)\n",
    "    dsm=dsmFile.read(1)\n",
    "    \n",
    "\n",
    "    # filter both datasets\n",
    "    dtm[dtm<0.0] = np.nan\n",
    "    dsm[dsm<0.0] = np.nan\n",
    "    \n",
    "    # Subtract the two to get height, as two are aligned\n",
    "    hData=dsm-dtm\n",
    "      \n",
    "    # pass back to the calling function\n",
    "    return(hData,dtmFile)\n",
    "\n",
    "\n",
    "\n",
    "# define filenames to use\n",
    "dsmName='data/ALS/DSM/coarsen.NN89_10M_DSM_PHASE1.tif'\n",
    "dtmName='data/ALS/DTM/coarsen.NN89_10M_DTM_PHASE1.tif'\n",
    "\n",
    "\n",
    "# call the user defined function to calculate the height array and metadata and read in to RAM\n",
    "# \"hData\" is a raster array of height values and \"rast\" is the rasterio object containing the geolocation and meta data\n",
    "hData,rast=heightAboveGround(dtmName,dsmName)\n",
    "\n",
    "\n",
    "# Add some lines below here to make an image of the CHM\n",
    "plt.imshow(hData)\n",
    "plt.colorbar(label='Height (m)')     # add a colour bar\n",
    "plt.show()         # print to screen "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a function to calculate canopy height from a single DSM and DTM. We then want to process all of the data. As a first step, let us practice processing all of the data to height and making an image of each tile to see how a loop can be used to batch process.\n",
    "\n",
    "The code below will create a list of all of the DTM and DSM filenames. **Add a loop to step through these filenames and call the ***heightAboveGround()*** function defined above to calculate height, then plot an image of each tile.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "dtmDir='data/ALS/DTM'\n",
    "dsmDir='data/ALS/DSM'\n",
    "\n",
    "dtmList=sorted(glob(dtmDir+'/*.tif'))\n",
    "dsmList=sorted(glob(dsmDir+'/*.tif'))\n",
    "\n",
    "\n",
    "# add a loop to calculate and plot a CHM for each tile\n",
    "\n",
    "# prepare a plot space\n",
    "nFigs=len(dtmList)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0,len(dtmList)):\n",
    "    dtmName=dtmList[i]\n",
    "    dsmName=dsmList[i]\n",
    "    \n",
    "    # print the filenames to screen\n",
    "    print(dtmName,dsmName)\n",
    "    \n",
    "    # add some lines to calculate the height and plot an image\n",
    "    hData,rast=heightAboveGround(dtmName,dsmName)\n",
    "\n",
    "   \n",
    "    # Add some lines below here to make an image of the CHM, with the y axis correctly aligned.\n",
    "    plt.imshow(hData)\n",
    "    plt.colorbar(label='Height (m)')     # add a colour bar\n",
    "    plt.show()         # print to screen \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the merged CHM\n",
    "\n",
    "In the cell above, you have looped over each tile and calculated the CHM. At the moment, you have plotted this on the screen, then the computer has deleted the data. We now want to save all of that data to disk so that we can use it in our later analysis. We have an irregular set of tiles that we want to intersect with our field data in order to map biomass.\n",
    "\n",
    "There are lots of different ways to do this, but to simplify the intersection of the CHM raster with our field data, we shall create a set of CHM raster tiles and then merge all of these in to a single CHM raster tile. This is less RAM efficient than keeping all of the tiles separate, but avoids having to loop over the tiles when intersecting the field data with the CHM.\n",
    "\n",
    "For the first step, we need to create a set of geotiffs for the CHM of each tile. The code below defines a function to write a single CHM to a new geotiff. **This is an example of code reuse**. `writeCHMtiff` makes use of `heightAboveGround`, and the eventual call to `writeCHMtiff` is one line, replacing about tens of lines of code that would be required to read two GeoTiffs (the DTM and DSM), subtract them, and then write to a new GeoTIFF. We can be even more efficient by creating a loop which creates and saves CHM rasters for **all** tiles -- saving hundreds of lines of code.\n",
    "\n",
    "The code below loops over the tiles to make a set of CHMs and write new geotiffs to disk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def writeCHMtiff(dtmName,dsmName,outName):\n",
    "    '''A function to write a CHM geotiff, based on heightAboveGround()'''\n",
    "\n",
    "    hData,datafile=heightAboveGround(dtmName,dsmName)\n",
    "\n",
    "    newfile=rasterio.open(outName,mode=\"w\",driver=\"GTiff\",height=datafile.height,width=datafile.width,\\\n",
    "                  count=1,dtype=hData.dtype,crs=datafile.crs,transform=datafile.transform)\n",
    "    newfile.write(hData, 1)\n",
    "\n",
    "    \n",
    "    print('Written to',outName)\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "# get a list of tilenames\n",
    "dtmDir='data/ALS/DTM'\n",
    "dsmDir='data/ALS/DSM'\n",
    "\n",
    "dtmList=sorted(glob(dtmDir+'/*.tif'))\n",
    "dsmList=sorted(glob(dsmDir+'/*.tif'))\n",
    "\n",
    "\n",
    "# modify this code to loop over all tiles to make a CHM\n",
    "for i in range(0,len(dtmList)):\n",
    "    dtmName=dtmList[i]\n",
    "    dsmName=dsmList[i]\n",
    "   \n",
    "    tileLabel=dtmName.split('/')[-1].split('_')[0]\n",
    "    outName=tileLabel+'_10M_CHM_PHASE1.tif'\n",
    "\n",
    "    writeCHMtiff(dtmName,dsmName,outName)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have a set of CHM geotiff files. The code below will read a list of your CHM geotiffs and merge them all in to a single raster geotiff, which will then be stored in:\n",
    "\n",
    "    data/ALS\n",
    "\n",
    "Note that this is making an external call from python to linux to call the gdal_merge.py python script using the *os* package. We can call any linux command in this way. This is a little bit inefficient but it is a bit more compact than calling the gdal merge function from within this python function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "\n",
    "chmDir='.'\n",
    "chmList=glob(chmDir+'/*CHM_PHASE1.tif')\n",
    "\n",
    "outName='data/ALS/merged_CHM_10m.tif'\n",
    "\n",
    "\n",
    "# turn the above in to a string so that the command below works\n",
    "chmStr=\"\"\n",
    "for f in chmList:\n",
    "    chmStr=chmStr+\" \"+f\n",
    "\n",
    "\n",
    "command = \"gdal_merge.py -o \"+outName+\" -init -999 -of gtiff \" + chmStr\n",
    "os.system(command)\n",
    "\n",
    "print('Written to',outName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibrating the biomass model\n",
    "\n",
    "Now you have a 10 m resolution CHM. You also have some field data in a csv file stored in:\n",
    "\n",
    "    data/ground/ground_data.csv\n",
    "    \n",
    "You can calibrate the model to predict biomass from lidar height. The ground data can be read in using the ***numpy.loadtxt()*** function to store the biomass (AGBD) and coordinates (x and y) in RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "groundname='data/ground/ground_data.csv'\n",
    "\n",
    "# load data in to RAM\n",
    "agbd,x,y=np.loadtxt(groundname, usecols=(1,2,3), unpack=True, dtype=float,skiprows=1,delimiter=',')\n",
    "\n",
    "# Here agbd is in kg/ha. Let's use the more common Mg/ha\n",
    "agbd=agbd/1000\n",
    "\n",
    "print(agbd,'Mg/ha')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to intersect this with our CHM raster to create an array with the biomass for each plot along with the mean CHM. We can then plot that data to see what type of mathematical model would be appropriate to predict biomass from lidar data.\n",
    "\n",
    "The script below will read in the raster layer and then return an array of CHM values corresponding to the coordinates you read in from the field data file. In this code we are finding a the nearest grid point in the CHM for each ground data point, and using the value in that pixel.\n",
    "\n",
    "**Add some code to make a scatterplot of biomass against mean canopy height. What type of relationship do you see?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# read the CHM geotiff in to RAM\n",
    "chmName='data/ALS/merged_CHM_10m.tif'\n",
    "chmFile=rasterio.open(chmName)\n",
    "chmData=chmFile.read(1)\n",
    "\n",
    "# find the top left corner coordinate\n",
    "xOrigin=chmFile.transform[2]\n",
    "yOrigin=chmFile.transform[5]\n",
    "\n",
    "# get a list of pixel coordinates for the ground plots (there are other packages for intersecting raster and vector data)\n",
    "xInds=np.array((x-xOrigin)/chmFile.res[0],dtype=int)\n",
    "yInds=np.array((yOrigin-y)/chmFile.res[1],dtype=int)\n",
    "\n",
    "# extract the values to make a new array of mean canopy height\n",
    "meanCH=chmData[yInds,xInds]\n",
    "\n",
    "# add some code to make a scatterplot of biomass (agbd) against mean canopy height (meanCH)\n",
    "plt.plot(meanCH,agbd,'.')\n",
    "plt.ylabel('Biomass (MG/ha)')\n",
    "plt.xlabel('Mean canopy height (m)')\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have viewed the data and chosen an appopriate mathamatical model (was it linear, logarithmic etc.?), if it is linear you can perform linear regression to get the equation for your biomass model. \n",
    "\n",
    "The code below shows you can example of fitting a line of best fit to two random datasets, and calculates the correlation (Pearson's $r$ value). Pearson's $r$ is the correlation between $x$ and $y$, which is also returned by `linregress`. The difference is that `pearsonr` returns its value *and the statistical significance*. $R^2$ is the square of Pearson's $r$.\n",
    "\n",
    "**Modify that code to find the equation needed to predict biomass from mean canopy height and report the strength of the correlation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# packages to do linear regression and Pearson's correlation\n",
    "from scipy.stats import linregress, pearsonr\n",
    "\n",
    "# make some fake data\n",
    "x=np.random.random((20))*100\n",
    "y=x*3+20+40*(np.random.random((20))-0.5)\n",
    "\n",
    "# fit a line of best fit. See manual for scipy.stats.linregress for more details\n",
    "m, c, r, _, _ = linregress(x,y)\n",
    "\n",
    "print(\"Line of best fit parameters are m\",round(m,3),\"c\",round(c,3))\n",
    "\n",
    "# find the correlation. See manual for scipy.stats.pearsonr\n",
    "print('Correlation is ',pearsonr(x,y))\n",
    "\n",
    "# the first number returned by pearsonr is the correlation, 99.28% for this fake data\n",
    "\n",
    "\n",
    "# repeat with the real data\n",
    "m, c, r, _, _ = linregress(meanCH,agbd)\n",
    "print(\"Line of best fit parameters are m\",round(m,3),\"c\",round(c,3))\n",
    "print('Correlation is',pearsonr(meanCH,agbd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Making the biomass map\n",
    "\n",
    "\n",
    "Now you have the parameters needed to parameterise a biomass model. **In the cell below, write some code to read in the CHM again (you can reuse the code above) and make a new array of biomass using the model you have just calibrated.** If this was a linear model, the biomass will be:\n",
    "\n",
    "$biomass = m \\times meanCH + c $\n",
    "\n",
    "You can use ***plt.imshow()*** to print it as an image on your screen, or modify the CHM writing function above to write the biomass raster layer as a new geotiff. Use whichever approach you prefer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the CHM geotiff in to RAM\n",
    "chmName='data/ALS/merged_CHM_10m.tif'\n",
    "chmFile=rasterio.open(chmName)\n",
    "data=chmFile.read(1)\n",
    "\n",
    "# filter missing data\n",
    "data[data<0.0]=np.nan\n",
    "\n",
    "# apply the model\n",
    "biomass=m*data+c\n",
    "\n",
    "\n",
    "# print to screen \n",
    "plt.imshow(biomass)\n",
    "plt.colorbar(label='Biomass (Mg/ha)')     # add a colour bar\n",
    "plt.show()         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using numpy operations, what is the mean biomass for this valley? What is the maximum biomass for any 10 m pixel?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out missing data\n",
    "usableBiomass=biomass[np.isnan(biomass)==False]\n",
    "\n",
    "\n",
    "# find the mean and max\n",
    "meanBiomass=np.mean(usableBiomass)\n",
    "maxBiomass=np.max(usableBiomass)\n",
    "\n",
    "print(\"Mean\",round(meanBiomass,2),\"t/ha. max\",maxBiomass,\"t/ha\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing the biomass map to file for reuse\n",
    "\n",
    "We have displayed the biomass map to screen above. Often we will want to save it for later analysis, either in python or in GIS. We can do this using rasterio with the example below. We can now open this geotiff in GIS or other software."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# set a filename\n",
    "outName='biomass.tif'\n",
    "\n",
    "# create a new raster file, taking the geolocation information from the CHM file\n",
    "newfile=rasterio.open(outName,mode=\"w\",driver=\"GTiff\",height=chmFile.height,width=chmFile.width,\\\n",
    "                      count=1,dtype=biomass.dtype,crs=chmFile.crs,chmFile=chmFile.transform)\n",
    "newfile.write(biomass, 1)\n",
    "\n",
    "print('Written to',outName)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A comment on automation\n",
    "\n",
    "\n",
    "As you have seen above, making a biomass map with Python requires quite a few functions, some using some unintuitive aspects of the language. However, you now have a workflow to process a set of geotiff tiles through to biomass. You can rerun the whole workflow by pressing the double arrow button at the top of the screen.\n",
    "\n",
    "You can do this for any data by downloading new tiles and putting them in the directories above. You can make adjustments to the workflow instructions (eg. change the resolution you do the calculation at, or add in an extra bit of processing) and then reurn everything with a single button."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visually assessing the results\n",
    "\n",
    "You have now produced a biomass map entirely in Python. Whilst python does allow you to make plots of maps and to calculate summary statistics, it can be clunky to assess one map against other. For that task, GIS allows you to more interactively work with the data.\n",
    "\n",
    "Download the biomass map you have made (go to the tab to the left of this, navigate to the map and tick and download it). Load this in to QGIS (either on your own computer or Apps.ed) and overlay it with a Bing aerial image.\n",
    "\n",
    "Can you see any obvious errors in the biomass map? Can you see a way to limit your analysis to a particular estate or a particular land type?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
